---
title: Five Parameters
author: David Kane and Sanaka Dash
tutorial:
  id: five-parameters
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 9 Tutorial: Five Parameters'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)
library(primer.data)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

df1 <- governors |> 
  select(last_name, year, state, sex, lived_after, election_age)

# fit_all <- brm(data = df1,
#                formula = lived_after ~ sex*election_age,
#                silent = 2,
#                refresh = 0,
#                seed = 13)
# 
# write_rds(fit_all, "data/fit_all.rds")

fit_all <- read_rds("data/fit_all.rds")

newobs = tibble(sex = c("Male", "Female"), 
                election_age = 50)
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- DK: FIX - Knowledge Drop Hashes need to be removed -->

<!-- DK: Key problems with current version: We need (?) to flesh out the Courage and Temperance sections. Key skills to practice each time including writing math formulas in Quarto and creating nice looking tables of regression results. -->


## Introduction
### 

This tutorial covers [Chapter 9: Five Parameters](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 


## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

### 

<!-- DK: FIX - old material, will insert general question later -->

Consider the following general question:

> What is the relation between sex and



> How long do political candidates live after the election?

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem. 

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: You have the opportunity, in this and the next few questions, to drop a lot of knowledge about the data and the overall topic. Do so! But, remember, students won't read more than 2 or so sentences in a knowledge drop. -->

<!-- Not only are you discussing the data, but you are also discussing potential problems with the data, problems which will be more fully fleshed out in the Justice section. You want to pick 5 to 10 interesting facts about the data. (You may need to go to the original source, not simply relying on the chapter. ) 

It is always a good idea to knowledge drop a link to the actual data and to any articles/books/websites related to it.

You won't be drawing any conclusions or discussing the explicit violation of any assumptions. That discussion is saved until Justice and the specific questions about stability, representativeness, and (with causal models) unconfoundedness. You are, however, providing the details which you and the students can then use later. -->

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.


```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

Create a Github repo called `tutorial-9`. Connect it to an new R Project called `tutorial-9`. Edit the `.gitignore` file to ignore the Rproj file.

In the Console, run `tutorial.helpers::show_file(".gitignore")`. CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX - Bad Knowledge Drop -->
<!-- As data scientists, it is crucial that we carefully analyze our data. Let's start with our Data. -->

### 

### Exercise 5

<!-- SD: FIX - Need to first introduce `library(primer.data), need to explain that it's part of `primer.data` -->

Let's first learn some background on how our dataset was collected. Type `?governors` in the Console, and paste in the description below.

```{r wisdom-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- SD: FIX - unfinished Knowledge Drop -->

As we learned, the data was collected from a study where XX




### 

Here's our Preceptor Table for today:
```{r}
#| echo: false

tibble(ID = c("Candidate 1", "Candidate 2", "...", "Candidate 10", "Candidate 11", "...", "Candidate N"),
       lived_after = c("12", "7", "...", "10", "11", "...", "6"),
       year_elected = c("2000", "2012", "...", "2012", "2024", "...", "2050"),
       election_age = c("63", "47", "...", "52", "75", "...", "68"),
       sex = c("Female", "Male", "...", "Female", "Female", "...", "Male")) |>
  gt() |>
  tab_header(title = "Preceptor Table") |>
  cols_label(ID = md("ID"),
             lived_after = md("Years Lived After"),
             year_elected = md("Year of Election"),
             election_age = md("Age at Election"),
             sex = md("Sex")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(lived_after)) |>
  tab_spanner(label = "Covariates", columns = c(sex, year_elected, election_age))
```

### 

With the Preceptor Table, we can calculate anything related to longevity because we know how many years each candidate lived after an election. But, in reality, many of these candidates are still alive, so we don’t know how long they will live.


### Exercise 6

What are the units for this problem?

HINT: Ask yourself "Who's being affected in this scenario?"

```{r wisdom-6}
question_text(NULL,
	message = "Our units for this problem would be individual candidates because the questions are about the life expectancy of those candidates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note also that the Preceptor Table stops with elections in 2050. So, implicitly, we have changed our question to:

*How many years would we expect political candidates in election years between 2000 and 2050 to live?*

The question, the Preceptor Table and the data evolve together in an iterative process.

### Exercise 7

What is the outcome for this problem?

HINT: Ask yourself "What are we trying to get out of this problem?"

NOTE: The outcome is what WE want to get out of the data, based on our QUESTION. It does NOT concern the POSSIBLE values that we CAN extract.

```{r wisdom-7}
question_text(NULL,
	message = "The number of years a candidate lives after the election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: A good knowledge drop for this exercise might involve other outcomes which might be useful for related questions. For example, if the outcome for a presidential election are votes cast than, with a slightly different question, the outcomes might be the electoral votes. We want to show them the interplay between the exact question and which outcomes define the Preceptor Table. -->

<!-- Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question we started with. No data science project follows a single direction. We always backtrack. There is always dialogue. -->

<!-- SD: FIX - OLD: -->

<!-- Knowledge: Talk about the data/paper. Above. -->
<!-- SD: This is done later instead of here -->



### Exercise 8

<!-- DK: Update with new approach. -->
<!-- SD: Instead of creating a new approach, would this work? -->

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

<!-- SD: FIX - Completely wrong information -->

<!-- SD: FIX - Unfinished -->
NOTE: The covariates are the values that we can extract to form a

```{r wisdom-8}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX -  -->

<!-- XX. For your information, the term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables which we have data for. Third, it is the set of covariates which we end up using in the model. -->

### Exercise 9

What are the treatments, if any, for this problem?

```{r wisdom-9}
question_text(NULL,
	message = "Since this is a predictive model there is no treatment per se. Any variable which one might consider a treatment is just another covariate in this context.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX -  -->

<!-- XX: Again, we dialogue. Any question, or broad topic, will use words. And words are not precise! Lots of possible treatments, each different from the other, are close to the original words. Drop some knowledge, or even speculation, about what sorts of treatments might be relevant in similar problems.  -->

<!-- DK: Note how the paper actually uses winning the election as a non-randomly assigned treatment. -->

### Exercise 10

What moment in time does the Preceptor Table refer to? (Obviously, you should refer to the *Primer* itself when answering questions like this.)

<!-- SD: FIX - Maybe add a hint that it's unclear -->

```{r wisdom-10}
question_text(NULL,
	message = "Moment in Time: It is unclear to what moment in time the question refers. Is it interested in all candidates who are running in the next election? All those running in the future? Let's choose to focus in candidate longevity in this century.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 11

Describe in words the Preceptor Table for this problem.

```{r wisdom-11}
question_text(NULL,
	message = "XX. Make sure your words given an excellent description of the Preceptor Table which you are about to show the student.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

<!-- SD: FIX -  -->

<!-- XX. Show the Preceptor Table. You can just copy/paste the code from the Primer, or use that code as a guide for creating your own ...-->

<!-- XX: Note that, like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which columns must be in the Preceptor Table. -->

### Exercise 12

<!-- DK: It is a feature that this question almost forces students to go to the chapter and read about the data. -->

Write one sentence describing the data you have to answer your question.

```{r wisdom-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX -  -->

<!-- XX. Insert a question or two which accomplishes the second chunk of QMD work. This begins with the creation of an `analysis.qmd` file (although you can use any name for it), its rendering to ensure that your computer setup is correct. The addition of *_files to the .gitignore so that we do not commit those junk files. It ends with a commit and push. show_file(".gitignore", start = -5) is not a bad last question. -->

### Exercise 13

<!-- DK: Split up into three questions. -->

Load the **tidyverse** package, as well as the **primer.data** package, which includes the `governors` dataset. On the third line, use `head()` on `governors`.

```{r wisdom-13, exercise = TRUE}

```

```{r wisdom-13-hint-1, eval = FALSE}
library(...)
library(...)
head(...)
```

```{r wisdom-13-test, include = FALSE}
library(tidyverse)
library(primer.data)
head(governors)
```

<!-- SD: FIX - Make New question, explain why it was better to use head() rather than summary(), etc. -->

The reason we used `head()` was to display only the first couple lines of `governors`, as we only need it to find the variables. If we plainly printed `governor`, we would be wasting rendering resources.

### 

<!-- XX: Insert comments about the data. This continues to be the primary type of knowledge drop. These comments can also be sophisticated, especially in the way that they connect the data to the Preceptor Table and to the population. -->

<!-- XX: Load any other packages that are needed, one package per question. (But make sure that they are also included in the setup chunk.) primer.data, for example, is often needed. But save brms and tidybayes for the Courage section. -->

<!-- XX: It is now time for the third set of QMD edits. Add a new code chunk, the setup chunk, to the QMD. Copy/paste all the library commands to it. Render. Note all the ugliness. Add #| message: false. Add execute: echo: false to the YAML header. Add #| label: setup. Render again. Everything looks nice. Again, these could be several questions in the earlier tutorials or just one long question later. Ends with show_file("analysis.qmd", start = -5). This will be the most common ending question in QMD-editing exercises to come. -->

<!-- XX: Add code questions about EDA with your data. In particular, add at least one question about the dependent variable in the model along with one or more questions about covariates. If there is a treatment variable, you must include a question about it. -->

<!-- Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. For example: "Civility is measured on a 1 through 7 scale with higher values corresponding to greater civility." -->

<!-- XX: If necessary, provide code exercises which, line-by-line, create the pipeline which creates the cleaned data that will be used in modeling. For many tutorials, this is unnecessary since we can just use the raw tibble that is available in whatever package. But we sometimes need some code like

nes |> 
  filter(year == 1992) |> 
  drop_na()

We have three code exercises, each adding one line to the pipeline, explaining what we are doing and why. It is nice that, for each exercise, something is spat out.
-->

<!-- XX: If such a pipeline was built, there is one QMD question which requires that you add a new code chunk to the QMD, copy/paste the pipeline and assign the result to some object like `model_data` or whatever:

nes_92 <- nes |> 
  filter(year == 1992) |> 
  drop_na()

`Command/ctrl + Shift + K` follows, perhaps with a show_file("analysis.qmd", start = -5)
-->


### Exercise 14

<!-- SD: FIX -  -->

<!-- DK: No questions. Just instructions. -->

Write down 3 things you observed from the data:

```{r wisdom-14}
question_text(NULL,
	message = "A few things I noticed about this data:
1) The data is sorted Alphabetically by State & by Year
2) The first & last names are in separate columns
3) A lot of the data is in the past century",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Insert comments about the data. -->
<!-- SD: I made this a question instead -->

<!-- DK: Consider adding more questions about EDA with this data. In particular, add at least one question about the dependent variable in the model along with one or more questions about covariates. If there is a treatment variable, we must include a question about it. -->

<!-- Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. -->

### Exercise 15

In your own words, define "validity" as we use the term.

```{r wisdom-15}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Is the meaning of the columns consistent, i.e., can we assume validity? That is the heart of validity. To put it simply, does the `lived_after` column in our Preceptor Table equate to same column in our data set?


### Exercise 16

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-16}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 17

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer. 


```{r wisdom-17}
question_text(NULL,
	message = "Using data from all deceased gubernatorial candidates in the United States between 1945 and 2012, we seek to forecast candidate longevity post-election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX -  -->

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `XX.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.

<!-- XX: As always, we like to do something in the tutorial before we do it in the QMD. But, in this case, we can just include the directions in the knowledge drop for the last question. -->

## Justice
### 

*It is in justice that the ordering of society is centered.* - Aristotle


### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- SD: FIX -  -->

<!-- XX: All of Justice is about concerns that you have, reasons why the model you create might not work as well as you hope. Drop knowledge/discussion as you see fit, but the central theme is *worries*. Connect some of the specific data discussion from Wisdom to these assumptions. -->

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

*The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes.*

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

<!-- SD: This might not be the best answer. We should probably change it later but for the time being it's good enough. -->
<!-- SD: FIX -  -->

```{r justice-4}
question_text(NULL,
	message = "Average lifespan is 1950 is different than the average in 2020.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In fact, between 1960 and 2015, life expectancy for the total population in the United States increased by almost 10 years. Therefore, our estimates for the future may need some adjustment — that is, to add years to our predicted life expectancy to account for a global change in lifespan over time.

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

*The more expansive your Preceptor Table, the more important the assumption of representativeness becomes.*

<!-- XX: Keep one of these. -->

<!-- Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case. -->

<!-- Stability looks across time periods. Reprentativeness looks within time periods. -->

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Only the two candidates with the most votes are included in the data set. This is unfortunate, as we would ideally look at all gubernatorial candidates (regardless of votes).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true.


### Exercise 8

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention at least one specific problem which casts doubt on your approach. 


```{r justice-8}
question_text(NULL,
	message = "Using data from all deceased gubernatorial candidates in the United States from elections held between 1945 and 2012, we seek to forecast candidate longevity in state-wide US races post-election. There is concern that longevity for gubernatorial candidates will differ significantly from that for candidates in Senate and other state-wide elections.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

Note: Your paragraph doesn't necessarily have to be as long as mine is :)

### 

<!-- SD: FIX -  -->
Edit the summary paragraph in `XX.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.

## Courage
### 

*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill


<!-- Questions about models, tests, and the DGM. -->


### Exercise 1

<!-- DK: Not sure I like this answer. -->
<!-- SD: How about this?: Justice verifies the Population Table. Courage creates a mathematical model which connects the outcome variable to the covariates, if any. Then, using code, we create a fitted model, including posterior probability distributions for all the unknown parameters. -->
<!-- SD: Official Answer: "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism." -->
<!-- SD: FIX -  -->

In your own words, name the key goal of Courage and the process we use to get there.

```{r courage-1}
question_text(NULL,
	message = "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 2

<!-- SD: FIX - I feel that we should load all packages at once rather than load them separately. -->

Load the **brms** package. Load this into the Console as well, as we will be using it later in the Console.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

Without going too deep into specifics, the `brms` package helps in creating wide range of complex Bayesian models.

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

<!-- SD: Did we introduce the concept of Bayesian Models in an earlier chapter? If we didn't it would be nice to introduce what Bayesian Models are. -->

<!-- SD: FIX -  -->
<!-- XX: Some comments about this problem. -->

<!-- XX: Might need an exercise which gets/creates/cleans the data you need for fitting the model. - DONE -->


<!-- DK: Question which adds all the libraries at once to the qmd and then show_file(). -->
<!-- SD: FIX -  -->


### Exercise 4

Add `library(brms)` and `library(tidybayes)` to `XX.qmd`. `Command/Ctrl + Shift + K`. At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", pattern = "brms|tidybayes")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX: For a knowledge drop, there is nothing wrong with discussion regular expressions, which is the magic which allows us to just pull out the two lines in the QMD which we want. But better would just be more Courage knowledge drops. -->


### Exercise 5

<!-- SD: FIX - minor errors that this section may have -->

*Does sex help us to forecast longevity?*

We will be creating a model using `brm()` from the **brms** package, but first, we need to set our data. Begin by setting a new variable called `df1`, and assign it to the `governors` dataset (we skimmed this earlier). Now, pipe this to `select()` with the following arguments: `last_name, year, state, sex, lived_after, election_age`.


```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
df1 <- ... |> 
  select(..., year, ..., sex, ..., election_age)
```


### Exercise 6

We will now be creating the model using `brm()` from the **brms** package. Observe the following model. 

> fit_all <- brm(data = df1,
                 formula = lived_after ~ sex*election_age,
                 silent = 2,
                 refresh = 0,
                 seed = 13)

Type `fit_all` and hit "Run Code." This generates the same results as using `print(fit_all)`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_all
```

```{r courage-6-test, include = FALSE}
print(fit_all)
```

### 

<!-- FIX - XX Say some general words about the object. Note that we are about to go through the top 4 rows. -->
<!-- SD: This needs to be replaced -->
This suggests that, for female candidates (for whom sexMale equal 0), life expectancy after the election is about 16 years. However, there is a great deal of uncertainty associated with that estimate. The 95% confidence interval ranges from 10 to 22 years.

### Exercise 7

Run `family()` on `fit_all`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_all)
```

### 

<!-- XX: This is a great location for explanations which get much more detailed in later chapters. That is, we want students to have a more sophisticated understanding of probability distributions, and there use in modeling, as we move through the Primer.

But, at a minimum, you would comment about how the family that is shown --- which is either gaussian, bernoulli or categorical --- is determined by the family argument which you passed in to the brm() call, and that you determined that by looking at the distribution of the output variable. Continuous means gaussian, 2 possible values means bernoulli, and 2+ possible values means categorical. -->

<!-- SD: FIX - -->

### Exercise 8

Run `formula()` on `fit_all`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_all)
```

### 

<!-- SD: FIX -  -->

This directly prints out the formula that we set earlier when creating the model, which is the link between the person's sex vs. how long they lived after their term.

### Exercise 9

Run `nobs()` on `fit_all`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_all)
```

### 

`nobs()` is an extremely useful command that tells us the number of useful, non-error observations that we have in the data. In our case, it should have returned "1092" as its answer.

### Exercise 10

<!-- SD: FIX -  -->
Write the mathematical formula for your model, using $\LaTeX$ math notation.

```{r courage-10}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add the formula to `XX.qmd`. `Command/Ctrl + Shift + K`. Ensure that the formula is looks correct. 

### Exercise 11

<!-- SD: FIX -  -->
Create a new code chunk in `XX.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model using `brm()` into the code chunk, assigning the result to `fit_all`. 

`Command/Ctrl + Shift + K`. It may take some time to render `XX.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `XX.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 12

Run `posterior_interval()` on `fit_all`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-12-test, include = FALSE}
posterior_interval(fit_all)
```

### 

<!-- SD: FIX - check if Khang made changes to this in his tutorial. -->
<!-- SD: The following was taken from Chapter 6 by Khang, and eventually we need to come up with something to write here across the board -->
A confidence interval, and its associated confidence level, tells us how likely the truth is to lie within a specific range.


### Exercise 13

Run `fixef()` on `fit_all`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-13-test, include = FALSE}
fixef(fit_all)
```

### 

<!-- SD: Don't know if this is completely right -->

With this command, we see that the predicted lifespan for females is higher than males (~16 vs ~12.5 years after term). Additionally, the female estimate has a lower estimated error rate, at ~2.91% vs ~2.93% for males.

<!-- SD: FIX -  -->

<!-- DK: Consider adding questions about conditional_effects(), ranef() and other commands, if relevant. -->

### Exercise 14

Run `pp_check()` on `fit_all`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-14-test, include = FALSE}
pp_check(fit_all)
```

### 

<!-- SD: This was copied directly from the Primer -->

Our graph in the darker blue represents our actual data. As we can see with the lighter blue graph, our fitted model is able to generate a distribution that is similar when compared to the actual data.

<!-- SD: The following was in the Template. It serves as a great addition to the above -->

If the fake data had looked very different from the real data, we have had a problem. But, for the most part, we conclude that, although not perfect, pp_check() shows that the fake outcomes generated by our model are like the actual outcome data.

<!-- SD: FIX - Not sure if the following belongs here: -->
<!-- DK: Add question to add model fitting code in new code chunk in qmd. Also include cache: true at the same time. -->

### Exercise 15

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-15-test, include = FALSE}
library(gtsummary)
```

### 

Essentially, the `gtsummary` package is used to make more advanced tables and assist with their creation far beyond the capability of what is built-in to R.

### Exercise 16

<!-- DK: This can be just one question or several, especially if you want to teach some more gtsummary or gt tricks. Make any adjustments to this question, like `intercept = TRUE`, so that this question works. -->

Run `tbl_regression()` on `fit_all`. 


```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
tbl_regression(...)
```

```{r courage-16-test, include = FALSE}
tbl_regression(fit_all)
```

### 

<!-- SD: FIX - Old Comment: -->
<!-- DK: Give something like the same sentence which you want the students to use at the end of the next question. -->

<!-- New Comment: -->
<!-- XX: Drop some knowledge about what you have learned by looking at the resulting table. Of course, you could have learned the same thing when you first took a look at fit_XX. But the table makes it easier to see the relationships between the variables and the outcome. With luck, students will take the hint when they answer the next question. -->

<!-- https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html -->

### Exercise 17

Write a few sentences which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add at least one sentence which describes the modelling approach which you are using, specifying at least the functional form and the dependent variable. Add at least one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-17}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 18

<!-- SD: FIX -  -->
Update `XX.qmd`. First, add `library(gtsummary)` to the `setup` code chunk,. Second, add the mathematical formula, in $\LaTeX$ and surrounded by double dollar signs, for your model. Third, add a new code chunk which creates the table of model parameters. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r courage-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

## Temperance
### 

*Temperance is simply a disposition of the mind which binds the passion.* - Thomas Aquinas


### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance guides us in the use of the data generating mechanism --- or the 'model' ---  we have created to answer the questions with which we began. We create posteriors for the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

<!-- SD: FIX - The following 8 Qs are from template_tutorial and are supposed to be what happens in this section: -->

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "XX: Should be exactly how you started the Wisdom section.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create a `newdata` object. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Must be all the right hand side variables in fit_XX. And note that the type must (maybe not always . . .) match, like if `treatment` is a factor in the original data used to create fit_XX then it must (?) be a factor in ndata. -->

### Exercise 4

How many rows do we need in the `newdata` object? Recall that each row will generate a posterior for something. That is, if you have two rows in your `newdata` object, you will get two posteriors. It is up to you to determine what those two posteriors are and what you want to do with them.

```{r temperance-4}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Chapter 10 is a great example of this in its full complexity. We want to know how "different" units behave, where the very definition of "different" is that they do not have identical values for all the variables used in fit_XX. -->

<!-- For example, one row in ndata will generally represent the answer to the specific question we started with. But that is just the posterior for one sort of unit. There are lots of different units! Which others might we be interested in? We can generate posteriors for each of them, and then, in some cool graphic, display all those posteriors together. -->


### Exercise 5

Here is the R code which creates the `newdata` object: `tibble(whatever) code here`. Type it into the code exercise block and hit "Run Code."

<!-- Asking students to create this object --- even after you help them figure out the columns, rows and values --- is too hard, at least until they get more experiences. Your knowledge drop, for this question and the next, should give them advice on the broad topic of how they can create newdata objects themselves. -->

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}

```

```{r temperance-5-test, include = FALSE}

```

### 

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

<!-- Of course, you need to have added the code to create `ndata` in the setup chunk at the top of the file. -->

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}

```

```{r temperance-6-test, include = FALSE}

```

### 

### Exercise 7

Now that we have the `newdata` object, we can create a pipe which uses out fitted model to answer our question. Begin by typing `fit_all` and clicking "Run Code."

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-hint-1, eval = FALSE}

```

```{r temperance-7-test, include = FALSE}

```

### 

<!-- XX: Again, the main point of knowledge drops is this area is to explain to students why the newdata object looks the way it does and what it will produce. A great way to teach is via example. That is, explaining that if we had another way with these values, then we would get this posterior. Or, explaining what would be produced if we used add_epred instead of add_predict, and vice verse. -->


### Exercise 8

Pipe `fit_all` to [XX: either `add_epred_draws()` or `add_predicted_draws()`] with the argument `newdata = ndata`.



```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}

```

```{r temperance-8-test, include = FALSE}

```

### 

<!-- XX: How do students know whether to use add_epred_draws or add_predicted_draws? This is non-trivial. On some level, we just tell them with the above command. (We don't make them guess.) But we also address this issue explicitly in various knowledg drops, especially this one. -->

<!-- XX: Insert as many questions as necessary to build a nice-looking example of your final plot. In early chapters, this is simple since our questions are simple. They are just one posterior. In later chapters, they become more complex, with the inclusion of several posteriors, as well as manipulation of them to calculate causal effects and whatnot. See the voting postcard example. -->

### Exercise 9

Create a new code chunk in `XX.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. `Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

FINAL GRAPH TEMP:

```{r}
#| echo: false
#| cache: true

df1 <- governors |> 
  select(last_name, year, state, sex, lived_after, election_age)

fit_all <- brm(data = df1,
                 formula = lived_after ~ sex*election_age,
                 silent = 2,
                 refresh = 0,
                 seed = 13)

draws <- fit_all |> 
  add_epred_draws(newdata = fit_all) |> 
  ungroup() |> 
  select(names, .epred) #|>  
  pivot_wider(names_from = names, 
              values_from = .epred, 
              values_fn = list) #|>
  unnest(cols = everything()) |> 
  janitor::clean_names()


# GRAPH:
  
draws |>

  ggplot(aes(x = .epred, y = sex)) +
  
    stat_slab(aes(fill = election_age),
              position = 'dodge') +
    scale_fill_calc() +
  
    scale_x_continuous(labels = scales::percent_format(accuracy = 1),
                       breaks = seq(-0.05, 0.11, 0.01)) +
  
    labs(title = "XX",
         subtitle = "XX",
         y = "XX",
         x = "XX",
         caption = "XX") +
  
    theme_clean() +
  
    theme(legend.position = "bottom")
```


### Exercise 10

<!-- SD: FIX - None of the following 5 Qs are supposed to be here -->
Recall the question with which we began:

*How many years would we expect two gubernatorial candidates — one male and one female, both 10 years older than the average candidate — to live after the election?*

To answer this question, we will start a new pipe with a data module called 'fit_all'. Let's assign this to `brm()` with the following arguments: `data = df1`, `formula = lived_after ~ sex*election_age`, `silent = 2`, `refresh = 0`,  `seed = 13`. 

```{r temperance-10, exercise = TRUE}

```

```{r temperance-10-hint-1, eval = FALSE}
fit_all <- ...(data = df1,
               formula = ... ~ ...*election_age,
               silent = ...,
               refresh = ...,
               seed = ...)
```

<!-- No test for brm calls. Take too long. -->

### Exercise 11

Now we need to create a scenario for our model. To do this, we will first create an object that we will assign in the next step. Let's call it `newobs`, and let's set it equal to `tibble()`. Inside `tibble()`, set the arguments `sex = c("Male", "Female")` and `election_age = 50`.

```{r temperance-11, exercise = TRUE}

```

```{r temperance-11-hint-1, eval = FALSE}
newobs = tibble(... = c("...", "Female"), 
                election_age = ...)
```

```{r temperance-11-test, include = FALSE}
newobs = tibble(sex = c("Male", "Female"), 
                election_age = 50)
```

### 

### Exercise 12

Now to tie it all together, we will pipe `fit_all` to `add_epred_draws()`. Inside this, we will add the argument `newdata = newobs`.

```{r temperance-12, exercise = TRUE}

```

```{r temperance-12-hint-1, eval = FALSE}
fit_... |> 
  add_epred_draws(newdata = ...)
```

```{r temperance-12-test, include = FALSE}
fit_all |> 
  add_epred_draws(newdata = newobs)
```

### 

Running this, you should get a list of people who entered office at the age of 50.

### Exercise 13

Now, where's the fun without a graph? In a couple steps, we will be producing this beautiful graph:

```{r}
fit_all |> 
  add_epred_draws(newdata = newobs) |> 
  ggplot(aes(.epred, fill = sex)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = 0.5, 
                   bins = 100, 
                   position = "identity") +
    labs(title = "Posterior for Expected Years Lived Post-Election",
         subtitle = "Male candidates live longer",
         x = "Years",
         y = "Probability") + 
    scale_x_continuous(labels = 
                         scales::number_format(accuracy = 1)) +
    scale_y_continuous(labels = 
                         scales::percent_format(accuracy = 1))
```

<!-- SD: I put it all in one exercise b/c I didn't want to waste the students' time, and also wanted to test how well they are able to follow directions. -->

After copying the previous code, continue the pipe into `ggplot()`, setting aesthetics to `.epred, fill = sex`. Now add `geom_histogram()`, and inside this, add `aes(y = after_stat(count/sum(count)))`, `alpha = 0.5`, `bins = 100`, and `position = "identity"`. Now add `scale_x_continuous(labels = scales::number_format(accuracy = 1))` and `scale_y_continuous(labels = scales::percent_format(accuracy = 1))`, and end it off with `labs()`.

```{r temperance-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-13-hint-1, eval = FALSE}
... |> 
  ggplot(...(.epred, fill = ...)) +
    geom_histogram(...(y = after_stat(count/...(count))),
                   alpha = ...elt(), 
                   ... = 100, 
                   position = "...") +
    labs(...) + 
    scale_x_continuous(... = 
                         ...::number_format(... = 1)) +
    scale_y_continuous(labels = 
                         scales::..._format(accuracy = ...))
```

```{r temperance-13-test, include = FALSE}
fit_all |> 
  add_epred_draws(newdata = newobs) |> 
  ggplot(aes(.epred, fill = sex)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   alpha = 0.5, 
                   bins = 100, 
                   position = "identity") +
    labs(title = "Posterior for Expected Years Lived Post-Election",
         subtitle = "Male candidates live longer",
         x = "Years",
         y = "Probability") + 
    scale_x_continuous(labels = 
                         scales::number_format(accuracy = 1)) +
    scale_y_continuous(labels = 
                         scales::percent_format(accuracy = 1))
```

### 

If all goes well, we have successfully recreated the graph! If you get stuck, be sure to check the hint.

### Exercise 14

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI. 

<!-- SD: FIX -  -->

<!-- XX: Most of the time, there will be some measure of uncertainty associated with your QoI. But not always! The most common counter-example involves a question which asks about the odds or probability of something happening. We would answer such a question by simulating the event with `add_predicted_draws()`. We would then calculate the odds/probability of something happening by seeing how many of the 4,000 draws met the criteria for the event. Assume that was 40%. So, we think that there is a 40% chance that event A will happen. Yet there is no uncertainty associated with that estimate because it, itself, is an expression of uncertainty. (DK: Flesh this out further.) -->

```{r temperance-14}
question_text(NULL,
	message = "You cannot edit this answer",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `XX.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.


<!-- XX: Again, spend time to make your recommended paragraph perfect. Study the examples in https://ppbds.github.io/primer/cardinal-virtues.html closely. -->

### Exercise 15

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

<!-- SD: FIX -  -->

```{r temperance-15}
question_text(NULL,
	message = "You cannot edit this answer",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 16

Rearrange the material in `XX.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd")
```

CP/CR.

```{r temperance-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 17

Publish `XX.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

## Summary
### 

This tutorial covered [Chapter 9: Five Parameters](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). This tutorial was created by Sanaka Dash and David Kane.



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
