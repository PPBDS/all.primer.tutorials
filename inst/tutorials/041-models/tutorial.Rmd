---
title: 'Models'
author: David Kane
tutorial:
  id: models
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 4 Tutorial: Models'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(brms)
library(tidybayes)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))


# fit_bern <- brm(formula = biden ~ 1,
#                 data = poll_data,
#                 family = bernoulli(),
#                 refresh = 0,
#                 silent = 2,
#                 seed = 12)
# write_rds(fit_bern, "data/fit_bern.rds")

fit_bern <- read_rds("data/fit_bern.rds")

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- DK: I left out the by-hand calculation of the confidence interval. Add it in? -->

<!-- Sort of shame that the model takes so long to run. Maybe find an example with fewer observations? If we did, we could run the model many times, examining one-by-one what some of the arguments do. Might even do that here with subsets of the data. -->

## Introduction
### 

This tutorial covers [Chapter 4: Models](https://ppbds.github.io/primer/models.html) of [*Preceptorâ€™s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "The units are individual voters.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that this is not all American adults or even all registered voters. To answer our question, we only need information about actual voters. Any other rows would be superfluous.

### Exercise 5

What is/are the outcome/outcomes for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "The outcome is the candidate for whom the vote was cast.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Looking at the question, this formulation is too broad. We don't actually need to know the name of the candidate. We just need to know if the vote was cast for Biden or not. The name of the candidate, if it was not Biden, is irrelevant to our question.

### Exercise 6

What are the covariates for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "There are no covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the question referred to who will win the election, then we would at least have to add a column for state of residence in order to tabulate electoral votes.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "There is no treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

This is a predictive model, not a causal model, so there are no treatments, by definition. Recall that treatment is just a covariate which, given the question we are trying to answer, might at least in theory be manipulable.

### Exercise 8

Write one sentence describing the data you have to answer your question.

```{r wisdom-8}
question_text(NULL,
	message = "We have data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, indicating which respondents intend to vote for Joe Biden and which do not.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 9

In your own words, define "validity" as we use the term.

```{r wisdom-9}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 10

What can't we do if the assumption of validity is not true?

```{r wisdom-10}
question_text(NULL,
	message = "We can't combine the Preceptor Table and the data in order to construct the Population Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 11

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-11}
question_text(NULL,
	message = "There is not a one-to-one correspondence between our data (which is about an reported intention to vote for Biden) and our Preceptor Table (which records an actual vote).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

What we tell other people we will do is often not what we actually do. Consider a voter who is embarrassed about her support for Biden. Perhaps she perceives the interviewer as a Republican and doesn't care to admit to him, in March, her support for Biden. But, in November, in the privacy of the polling booth, she votes for Biden. In her case, the outcome from the data (what she told the pollster) did not have a *valid* correspondence with her behavior in the polling booth.


### Exercise 12

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer. 


```{r wisdom-12}
question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. In particular, we want to estimate the odds that, if we meet two voters, both will have voted for Biden?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Justice
### 

*Justice is truth in action.* - Benjamin Disraeli


### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 3

Describe the Population Table for this problem. In particular, are any of the rows in the Preceptor Table also rows in the data? Are there other rows in the Population Table which are not from the Preceptor Table or the data? If so, describe some of those rows.

```{r justice-3}
question_text(NULL,
	message = "Each row in the Population Table corresponds to a person/date combination. None of the rows for the Preceptor Table and the data overlap. Rows from the overall population feature dates outside the survey dates and the election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-4}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 5

Provide one reason why the assumption of stability might not be true in this case. (This is somewhat of a trick question.)

```{r justice-5}
question_text(NULL,
	message = "Our Population Table is so simple that stability is true almost automatically true. There is only one column!",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability might become important as we think about the actual process by which we might meet the two voters in our original question, but, in terms of the Population Table itself, there is no problem.

### Exercise 6

In your own words, define the assumption of "representativeness" when employed in the context of data science.


```{r justice-6}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Keep one of these. -->

<!-- Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case. -->

<!-- Stability looks across time periods. Reprentativeness looks within time periods. -->

<!-- The more expansive your Preceptor Table, the more important the assumption of representativeness becomes. -->

### Exercise 7

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Keep one. -->

<!-- This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true.  -->

<!-- The easiest way to ensure unconfoundedness is to assign treatment randomly. -->

### Exercise 9

Provide one reason why the assumption of unconfoundness might not be true (or relevant) in this case.

```{r justice-9}
question_text(NULL,
	message = "Place correct answer here.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 10

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention at least one specific problem which casts doubt on your approach. 


```{r justice-10}
question_text(NULL,
	message = "XX.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Courage
### 

*Courage is found in unlikely places.* - J.R.R. Tolkien


### Exercise 1

<!-- DK: Not sure I like this answer. -->

In your own words, name the key goal of Courage and the process we use to get there.

```{r courage-1}
question_text(NULL,
	message = "Courage selects the data generating mechanism. We first specify the mathematical formula which connects the outcome variable we are interested in with the other data that we have. We explore different models. We need to decide which variables to include and to estimate the values of unknown parameters. We check our models for consistency with the data we have. We avoid hypothesis tests. We select one model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

The **brms** package provides a user-friendly interface to work with the statistical language [Stan](https://mc-stan.org/), the leading tool for Bayesian model building.

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

<!-- XX: Some comments about this problem. -->


### Exercise 4

Run this code in order to generate the polling data.

```{r courage-4, exercise = TRUE}
poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))

slice_sample(poll_data, n = 10)
```

```{r courage-4-test, include = FALSE}
poll_data <- tibble(biden = c(rep(1, 655), 
                              rep(0, 904)))

slice_sample(poll_data, n = 10)
```

### 

We don't care exactly who voted for Biden and who did not. In that sense, the rows of the data (and the Preceptor Table) are "exchangeable," which means (roughly) that nothing changes if we re-arrange the IDs of any of the rows.

### Exercise 5

Use `brm()` to fit a model, assigning the result to an object called `fit_bern`. Use the arguments: `formula = biden ~ 1`, `data = poll_data`, `family = bernoulli()`, `refresh = 0`, `silent = 2`, and `seed = 9`.


```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
fit_bern <- brm(formula = ...,
                ... = poll_data,
                family = bernoulli(),
                ... = 0,
                silent = ...,
                ... = 9)
```

This will take a little whole to run. It won't produce anything because of the `refresh` and `silent` arguments. 

### 

You really ought to run all the code in the chapter, the better to understand the details of the effects of different arguments.

### Exercise 6

Type `fit_bern` and hit "Run Code." This generates the same results as using `print(fit_bern)`.


```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
print(...)
```

```{r courage-6-test, include = FALSE}
print(fit_bern)
```

### 

<!-- XX Same some general words about the object. Note that we are about to go through the top 4 rows. -->

<!-- Add summary() Exercise if it gives a different answer -->

### Exercise 7

Run `family()` on `fit_bern`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_bern)
```

### 

<!-- DK: This is good material, but too long. And too complex for this first pass. -->

In this case, we see that the family of the error term is bernoulli. In a Bernoulli data generating mechanism, we have:

$$ biden_i  \sim Bernoulli(\rho) $$

Each voter $i$ which we sample either supports Biden or they do not. If person $i$ supports Biden, the value drawn is `1`, which is the standard way of representing `TRUE`.

The default link function for a Bernoulli model is logit, as in:

$$
\rho = \frac{e^{\beta_0}}{1 + e^{\beta_0}}
$$
By definition, the parameter $\rho$ is only allowed to take values between 0 and 1. We want to constrain the model so that only these values are even possible.

### Exercise 8

Run `formula()` on `fit_bern`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_bern)
```

### 

In this case, we have the simplest possible formula. `biden`, which is a zero/one binary variable is a function of a constant. There are no independent variables.

### Exercise 9

Run `nobs()` on `fit_bern`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_bern)
```

### 

In this case, the number of observations is `r scales::comma(nobs(fit_bern))`. 

### Exercise 10

Run `posterior_interval()` on `fit_bern`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-10-test, include = FALSE}
posterior_interval(fit_bern)
```

### 

There are several parameters in the model, almost all of them so-called "nuisance" parameters, meaning that we don't care about them. Their particular values don't really help us to directly calculate any quantity of interest.


### Exercise 11

Run `fixef()` on `fit_bern`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-11-test, include = FALSE}
fixef(fit_bern)
```

### 

The "Intercept" is the key part of the model. Because the family is (incorrectly!) Gaussian and the link function an identity, the actual model we are estimating looks like:

$$ biden_i =  \mu + \epsilon_i $$

with $\epsilon_i \sim N(0, \sigma^2)$. $y_i$ is the height of male $i$. $\mu$ is true proportion of Biden voters. $\epsilon_i$ is the "error term," the difference between the vote of person $i$ and the true proportion of Biden voters.

### Exercise 12

Run `pp_check()` on `fit_bern` with the `type` argument set to `"bars"`.  The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
pp_check(...,  type = "...")
```

```{r courage-12-test, include = FALSE}
pp_check(fit_bern,  type = "bars")
```

### 

In this case, there are two possible outcomes: 0/1. The actual values in the data are labeled `y`. We use our fitted model, `fit_bern` to generate 10 alternate data sets, 10 "fake" data sets. What might the number of votes for (and not for) Biden look like if `fit_bern` is true. The graphic demonstrates that the fake data is very similar to the real data, thus suggesting that our model has captured reality, at least somewhat. 

If the fake data had looked very different from the real data, we have had a problem.  


### Exercise 13

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-13-test, include = FALSE}
library(gtsummary)
```

### 

Read [this tutorial](https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html) for an introduction to `tbl_regression()`, the most important function in the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

### Exercise 14

Run `tbl_regression()` on `fit_bern` with `intercept = TRUE`. 


```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
tbl_regression(..., intercept = TRUE)
```

```{r courage-14-test, include = FALSE}
tbl_regression(fit_bern, intercept = TRUE)
```

### 

The [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package includes many functions for formatting our table. The better your work looks, the more seriously people will take it.


### Exercise 15

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add at least one sentence which describes the modelling approach which you are using. Also add at least one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-15}
question_text(NULL,
	message = "XX.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha

### Exercise 1

In your own words, describe the use of Temperance in finishing our data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance guides us in the use of the data generating mechanism --- or the 'model' ---  we have created to answer the questions with which we began. We create posteriors for the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

Recall the question with which we began:

> What are the odds, if we just look at two voters, both will have voted for Biden?

To answer this question, we need to create the `newdata` object which we will use with `fit_bern`. 

Type `tibble(.rows = 2)`. Hit "Run Code."

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
tibble(... = 2)
```

```{r temperance-2-test, include = FALSE}
tibble(.rows = 2)
```

### 

This creates an empty tibble with two rows. Because `fit_bern` is such a simple model, one with no independent varibles, the `newdata` object is also extremely simple. In this case, we are interested in the two people we might meet (and who they voted for) so we need to rows in `newdata`.

The number of rows in `newdata` corresponds to the number of units for which we seek to forecast the behavior/results.

### Exercise 3

Pipe `fit_bern` to `add_predicted_draws()` with `newdata = tibble(.rows = 2)`.


```{r temperance-3, exercise = TRUE}

```

```{r temperance-3-hint-1, eval = FALSE}
fit_bern |> 
  ...(newdata = tibble(.rows = ...))
```

```{r temperance-3-test, include = FALSE}
fit_bern |> 
  add_predicted_draws(newdata = tibble(.rows = 2))
```

### 

Note that there are 8,000 row, 4,000 for each individual, stacked on top of each other. The `.row` variable refers to the respective row in `newdata`.

### Exercise 4

Add `select(.row, .draw, .prediction)` to the pipe.

```{r temperance-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-4-hint-1, eval = FALSE}
... |> 
  ...(.row, ..., .prediction) 
```

```{r temperance-4-test, include = FALSE}
fit_bern |> 
  add_predicted_draws(newdata = tibble(.rows = 2)) |> 
  select(.row, .draw, .prediction) 
```

### 

Note that the tibble which is "spat" out at the end of this pipe is a grouped tibble. See the "Groups" label at the top. Unless we `ungroup()` the pipe, future commands will be executed on `.row = 1` rows separately from `.row = 2` rows.

### Exercise 5

Continue the pipe with `pivot_wider()` setting, `values_from = .prediction` and `names_from = .row`.

```{r temperance-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-5-hint-1, eval = FALSE}
... |> 
  pivot_wider(... = .prediction, names_from = ...)
```

```{r temperance-5-test, include = FALSE}
fit_bern |> 
  add_predicted_draws(newdata = tibble(.rows = 2)) |> 
  select(.row, .draw, .prediction) |> 
  pivot_wider(values_from = .prediction, names_from = .row)
```

### 

`pivot_wider()` gets rid of the grouping automatically. We now have a column for each of our two individuals, represented by `1` and `2`. The tibble has 4,000 rows because this is the default number of draws we create with functions like `add_predicted_draws()`.

<!-- DK: Sure would be nice to have a question which explains what this object means. -->

### Exercise 6

Continue the pipe with `mutate()` setting, "both = if_else(`1` & `2`, TRUE, FALSE)" as the argument. (Apologies for the formating of these instructions, The 1 and the 2 in this code must both be surrounded with backticks.)



```{r temperance-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-6-hint-1, eval = FALSE}
... |> 
  mutate(both = if_else(`1` & `2`, TRUE, FALSE)) 
```

```{r temperance-6-test, include = FALSE}
fit_bern |> 
  add_predicted_draws(newdata = tibble(.rows = 2)) |> 
  select(.row, .draw, .prediction) |> 
  pivot_wider(values_from = .prediction, names_from = .row) |> 
  mutate(both = if_else(`1` & `2`, TRUE, FALSE)) 
```

### 

### Exercise 7

Write a paragraph which summarizes your project. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI. 

```{r temperance-7}
question_text(NULL,
	message = "XX.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Summary
### 

This tutorial covered [Chapter 4: Models](https://ppbds.github.io/primer/models.html) of [*Preceptorâ€™s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
